---
title: 'Assignment 3: Univariate Models'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Read in Data "Trees"
```{r}
trees = read.csv('https://raw.githubusercontent.com/dmcglinn/quant_methods/gh-pages/data/treedata_subset.csv')
```

Create a subset of the data only containing the Acer rubrum species
```{r}
ACE<-subset(trees, species == 'Acer rubrum', select =c(species:beers))
ACE
```

Visual comparison of potential explanatory variables for coverage:
```{r}
pairs(ACE)
```

Below you will see my exploratory analysis of Acer rubrum, followed by my exploratory analysis of Abies fraseri.  I begin each analysis with a simple linear regression for each variable, I then build up to mulitvariable linear regression models. Explanations of data, my findings, and answers to the questions can be found in the paragraphs above each section.


I began my exploratory analysis of Acer rubrum by generating simple linear regression models for each variable in the dataframe.  Below are my findings.

Elevation, stream distance, and beers appeared to be the best predictors for cover using a linear model, however none of them explained the variation well.  Each variable had moderately low P-values, indicating that they have some effect on coverage.  Beers had the highest R-squared value (1.39%) indicating that only 1.4% of the variation could be explained with this model.  None of these would be a good model to predict cover for Acer rubrum. 

Analysis of the Residuals vs Fits, and Normal QQ Plots was performed to check if OLS assumptions were violated in any of the models.  Elevation, stream distance, and beers all showed relatively equal distributions and spreads along the Res. vs Fits, indicating constant variance and linearity could be a reasonable assumption.  From the QQ plots we saw slight deviations from the line but nothing to indicate a violation of normality.

The models using tci, and disturb as single predictors showed aberant behavior in the QQ plot. Both appeared to have quantized points, or partitioned deviations from the line, indicating a violation of the independent errors. Additionally, the Res. v. Fit for tci indicated non-constant variance as seen in the fan-like distribution of the residuals. These violations would preclude us from using these models as valid predictors. 

Cover predicted by elevation (plots and summary)
```{r}
ace.lm1<-lm(cover~elev, data = ACE)
ace.lm1
plot(ace.lm1)
summary(ace.lm1)
```


Cover predicted by tci (plots and summary)
```{r}
ace.lm2<-lm(cover~tci, data = ACE)
ace.lm2
plot(ace.lm2)
summary(ace.lm2)
```

Cover predicted by stream distance (plots and summary)
```{r}
ace.lm3<-lm(cover~streamdist, data = ACE)
ace.lm3
plot(ace.lm3)
summary(ace.lm3)
```


Cover predicted by disturbance (plots and summary)
```{r}
ace.lm4<-lm(cover~disturb, data = ACE)
ace.lm4
plot(ace.lm4)
summary(ace.lm4)
```


Cover predicted by beers (plots and summary)
```{r}
ace.lm5<-lm(cover~beers, data = ACE)
ace.lm5
plot(ace.lm5)
summary(ace.lm5)
```


Next, I generated models that included more than one variable to predict cover. These mulitvariable linear regression models were created using different combinations of elevation, stream distance, and beers.  The p-values and R-squared values were analyzed, and compared to those generated by anova.

None of the models below were able to confidently predict cover and explain variation.  The best model included all three variables, but even then only 3.68% of the variation could be explained.  This is still not a good model to predict cover.

Model Diagnostics show that there weren't any violations to the OLS assumptions with any of these models.  It appears that there is constant variance, linearity, and the errors are relatively normally distrubuted and therefore independent and random.


Cover predicted by elevation, distance, and beers:
```{r}
ace.mod.1<-lm(cover~elev+streamdist+beers, data=ACE)
ace.mod.1
plot(ace.mod.1)
```



Cover predicted by elevation and distance:
```{r}
ace.mod.2<-lm(cover~elev+streamdist, data=ACE)
ace.mod.2
plot(ace.mod.2)
```


```{r}
ace.mod.3<-lm(cover~elev+beers, data=ACE)
ace.mod.3
plot(ace.mod.3)
```

Cover predicted by stream distance and beers
```{r}
ace.mod.4<-lm(cover~streamdist+beers, data=ACE)
ace.mod.4
plot(ace.mod.4)
```

Summary vs. Anova for above models:

```{r}
summary(ace.mod.1)
anova(ace.mod.1)
summary(ace.mod.2)
anova(ace.mod.2)
summary(ace.mod.3)
anova(ace.mod.3)
summary(ace.mod.4)
anova(ace.mod.4)
```


Lastly, I created a few interaction models to see if the interaction between the variables would increase predictablity for cover.  Again, I focused on the variables that seemed to have the most effect.  The interaction model that included all three variables returned an R-squared value of 0.06861, indicating that only 6.86% of the variation in our model could be explained.  This is still not a great model, but it is an improvement from the rest.  I also created an interaction model using all variables, this resulted in the highest R-squared value, explaining 20% of the variation.  However, this model is not a practical one to use.

Model diagnostics don't seem to indicate any violation of the OLS assumptions.  There are some deviations seen in the QQ plot but nothing to indicate a violation of normality.  Based off of the low R-squared values I would not consider any of the following models to be good predictors for cover for the Acer rubrum species. 


Interaction model where cover is predicted by elevation, stream distance, and beers:
```{r}
int_mod_1<-lm(cover~elev*streamdist*beers, data=ACE)
int_mod_1
plot(int_mod_1)
```

Interaction model where cover is predicted by elevation and beers:
```{r}
int_mod_2<-lm(cover~elev*beers, data=ACE)
int_mod_2
plot(int_mod_2)
```

Interaction model where cover is predicted by stream distance and beers:
```{r}
int_mod_3<-lm(cover~streamdist*beers, data=ACE)
int_mod_3
plot(int_mod_3)
```


Interaction model where cover is predicated by elevation and stream distance:
```{r}
int_mod_4<-lm(cover~streamdist*elev, data=ACE)
int_mod_4
plot(int_mod_4)
```

Interaction model where cover is predicted by all variables present:
```{r}
ace_int_mod<- lm(cover~elev*tci*streamdist*disturb*beers, data= ACE)
ace_int_mod
plot(ace_int_mod)
```
 

Summary vs Anova for every model:

```{r}
summary(int_mod_1)
anova(int_mod_1)
summary(int_mod_2)
anova(int_mod_2)
summary(int_mod_3)
anova(int_mod_3)
summary(int_mod_4)
anova(int_mod_4)
summary(ace_int_mod)
anova(ace_int_mod)
```




An exploratory analysis was also performed on the Abies fraseri species.


A subset of the data only containing the Acer rubrum species was created.


```{r}
ABI <- subset(trees, species = "Abies fraseri")
```



To begin my exploratory analysis, I created simple linear regression models for each variable in the data frame.  I focused on the p-values and R-squared values of each model. Elevation appeared to be the single best predictor for cover, with the model explaining 1.8% of the variation.  The next best predictor was disturbance, followed by beers, with 0.74% and 0.32% of the variance explained, respectively.  

Next, a diagnostic was performed to determine if any of the models violated OLS assumptions.  Viewing the residuals vs fits plots we can see that all the variables, except tci, appear to be evenly distributed indicating that constant variance and linearity could be a reasonabe assumption. tci had a large gap in distribution indicating nonconstant variance, which is one of the violations of the OLS assumptions.  Using the QQ plot we checked to see if the errors were random, independant and normally distributed.  We can see that elevation was the only model that appeared to have normally distributed residuals with only slight deviation from the line.  All other variables demonstrated partitioned deviations from this line.  This could indicate that the errors of the model are not random, nor are they independent.  The lack of normality is another violoation of OLS assumptions.  The simple linear regression model using elevation as a predictor for cover is the best model based on p-value, variation explained, and the model diagnostics.

Cover predicted by elevation (plots and summary)
```{r}
abi.lm1<-lm(cover~elev, data = ABI)
abi.lm1
plot(abi.lm1)
summary(abi.lm1)
```

Cover predicted by tci (plots and summary)
```{r}
abi.lm2<-lm(cover~tci, data = ABI)
abi.lm2
plot(abi.lm2)
summary(abi.lm2)
```

Cover predicted by stream distance (plots and summary)
```{r}
abi.lm3<-lm(cover~streamdist, data = ABI)
abi.lm3
plot(abi.lm3)
summary(abi.lm3)
```


Cover predicted by disturbance (plots and summary)
```{r}
abi.lm4<-lm(cover~disturb, data = ABI)
abi.lm4
plot(abi.lm4)
summary(abi.lm4)
```


Cover predicted by beers (plots and summary)
```{r}
abi.lm5<-lm(cover~beers, data = ABI)
abi.lm5
plot(abi.lm5)
summary(abi.lm5)
```

Next, I generated a multivariable linear regression model using every variable in the data frame.  Then, I systematically simplified the model using only the significant variables determined by the p-values of the full model.  The variables deemed to be significant were elevation, disturbance, and beers. The p-values and R-squared values were analyzed, and compared to those generated by anova.

Model diagnostics showed that OLS assumptions were upheld in every model however there was more deviation in normallity when elevation was removed from the model.

Comparison of the summary and anova outputs were then performed on the mulitvariable models.  The full model yielded the highest percent of explained variance at 2.23%.  This would not be a good model to use though because it is relatively complex without much explaination.  The "best" model generated was the one that included elevation, disturbance, and beers as explanatory variables.  This was expected though based on the significance of these three variables seen in every model generated thus far.  Each of these variables had low p-values indicating they are significant to coverage and have some sort of effect.  This model has an R-squared value of 0.00218 indicating that only 2.18% of the variance could be explained. This would not be a good model to use to predict cover.

```{r}
full.abi.mod<-lm(cover~elev+tci+streamdist+disturb+beers, data=ABI)
plot(full.abi.mod)
```

```{r}
summary(full.abi.mod)
anova(full.abi.mod)
```

cover predicted by elevation, disturbance, and beers
```{r}
part.abi.lm1<- lm(cover~elev+disturb+beers, data= ABI)
plot(part.abi.lm1)
```


Cover predicted by elevation and disturbance
```{r}
part.abi.lm2<- lm(cover~elev+disturb, data= ABI)
plot(part.abi.lm2)
```

Cover predicted by elevation and beers
```{r}
part.abi.lm3<- lm(cover~elev+beers, data=ABI)
plot(part.abi.lm3)
```

Cover predictd by disturbance and beers
```{r}
part.abi.lm4<-lm(cover~disturb+beers, data=ABI)
plot(part.abi.lm4)
```

Summary versus anova:

```{r}
summary(full.abi.mod)
anova(full.abi.mod)
summary(part.abi.lm1)
anova(part.abi.lm1)
summary(part.abi.lm2)
anova(part.abi.lm2)
summary(part.abi.lm3)
anova(part.abi.lm3)
summary(part.abi.lm4)
anova(part.abi.lm4)
```



Lastly, I generated a multivariable model to include any interaction effects.  I started with all explanatory variables and systematiclly eliminated based on significance as seen by the p-values.  In every model it was evident that elevation, disturbance, and beers play a significant role in coverage prediction, however there wasn't a single model that could accurately predict coverage.  The interaction model that included all possible variables was only able to explain 4% of the variance.  Not a good model to use, especially with such complexity.  The "best" interaction model was the one that included elevation, disturbance, and beers as explanotory variables, but this only yeilded a 2.8% variance explained.  No violations of OLS assumptions were indicated in these models.

```{r}
full_inter.abi.mod<-lm(cover~elev*tci*streamdist*disturb*beers, data=ABI)
plot(full_inter.abi.mod)
```

```{r}
summary(full_inter.abi.mod)
anova(full_inter.abi.mod)
```


```{r}
inter.abi.mod1<-lm(cover~elev*disturb*beers, data=ABI)
plot(inter.abi.mod1)
```

```{r}
inter.abi.mod2<-lm(cover~elev*beers, data=ABI)
plot(inter.abi.mod2)
```


```{r}
inter.abi.mod3<-lm(cover~elev*disturb, data=ABI)
plot(inter.abi.mod3)
```


```{r}
inter.abi.mod4<-lm(cover~disturb*beers, data=ABI)
plot(inter.abi.mod4)
```

```{r}
summary(full_inter.abi.mod)
anova(full_inter.abi.mod)
summary(inter.abi.mod1)
anova(inter.abi.mod1)
summary(inter.abi.mod2)
anova(inter.abi.mod2)
summary(inter.abi.mod3)
anova(inter.abi.mod3)
summary(inter.abi.mod4)
anova(inter.abi.mod4)
```


Lastly, I recreated my four best models (two for Acer and two for Abies) to re-examine using a Poissan perspective.

```{r}
acer_poi = glm(cover ~ elev + streamdist + beers , data = ACE, 
           family='poisson')
acer_poi1= glm(cover~elev*streamdist*beers, data= ACE, 
           family ='poisson')

abi_poi = glm(cover~ elev + disturb + beers, data = ABI,
          family ='poisson')
abi_poi1= glm(cover~ elev*disturb*beers, data = ABI,
          family = 'poisson')
```

```{r}
pseudo_r2 = function(glm_mod) {
                1 -  glm_mod$deviance / glm_mod$null.deviance
}
```


```{r}
pseudo_r2(glm_mod = acer_poi)
pseudo_r2(glm_mod = acer_poi1)
pseudo_r2(glm_mod = abi_poi)
pseudo_r2(glm_mod = abi_poi1)
```
